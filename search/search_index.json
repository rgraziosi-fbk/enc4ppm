{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Encoding For Predictive Process Monitoring (enc4ppm)","text":"<p><code>enc4ppm</code> is a Python package than provides common process mining encodings.</p>"},{"location":"#installation","title":"Installation","text":"<p>Using pip:</p> <pre><code>pip install enc4ppm\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>The following example performs frequency encoding with latest payload for next activity prediction task:</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.frequency_encoder import FrequencyEncoder\nfrom enc4ppm.constants import LabelingType\n\n# Load log\nlog = pd.read_csv('bpic2012.csv')\n\n# Create encoder\nencoder = FrequencyEncoder(\n    labeling_type=LabelingType.NEXT_ACTIVITY,\n    include_latest_payload=True,\n    attributes=['AMOUNT_REQ'],\n)\n\n# Encode log\nencoded_log = encoder.encode(log)\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Frequency, simple-index and complex-index encodings</li> <li>Next activity, remaining time and outcome labelings</li> <li>Save encoder to disk for later use</li> <li>Freeze encoder on training set, then use it on unseen data (automatic handling of unknown values)</li> <li>Standardize numerical features</li> <li>Convert categorical features to one-hot encoding, or keep them as strings</li> <li>Add time features (time since case start and time since last event) to the encoding</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>This page provides example usages of the <code>enc4ppm</code> package.</p>"},{"location":"examples/#basic-example","title":"Basic example","text":"<p>The following example shows how to setup encoder to properly read log columns like case id, activity name, etc.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.frequency_encoder import FrequencyEncoder\nfrom enc4ppm.constants import LabelingType\n\nlog = pd.read_csv('log.csv')\n\nencoder = FrequencyEncoder(\n    labeling_type=LabelingType.NEXT_ACTIVITY,\n    case_id_key='CaseID',               # if not set, defaults to case:concept:name\n    activity_key='Activity',            # if not set, defaults to concept:name\n    timestamp_key='Complete Timestamp', # if not set, defaults to time:timestamp\n)\n\nencoded_log = encoder.encode(log)\n</code></pre>"},{"location":"examples/#encode-train-test-data-freezing-the-encoder","title":"Encode train-test data: freezing the encoder","text":"<p>When working with train-test data, we don't want the encoder to look at test data to avoid data leakage. It is usually a good idea to first encode training data and freeze the encoder on it, then use the frozen encoder to encode test data.</p> <p>Encoder can be frozen by calling <code>.encode()</code> with <code>freeze=True</code>. When an encoder is not frozen, calling <code>.encode()</code>  will build internal vocabularies of activities, attributes, and so on; on the other hand, if <code>.encode()</code> is called on a frozen encoder it will use the previously computed internal vocabularies.</p> <p>For example, test set may contain an activity <code>ActivityX</code> that is not present in training set. If frequency encoding is performed on the full log (training+test), then the encoded dataframe will contain a column <code>ActivityX</code> even though that activity should not be known during training.</p> <p>The following example avoids this problem by encoding training and test sets separately, freezing the encoder on the training data.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.simple_index_encoder import SimpleIndexEncoder\nfrom enc4ppm.constants import LabelingType, PrefixStrategy\n\ndef split_log(log):\n    # your split logic here\n\nlog = pd.read_csv('log.csv')\n\ntrain_log, test_log = split_log(log)                       # split the log before encoding\n\nencoder = SimpleIndexEncoder(\n    labeling_type=LabelingType.REMAINING_TIME\n)\n\nencoded_train_log = encoder.encode(train_log, freeze=True) # freeze encoder on train log\nencoded_test_log = encoder.encode(test_log)                # use frozen encoder on test log\n</code></pre> <p>The encoder is frozen on the train log. As a result, when encoding the test log, <code>ActivityX</code> will be mapped to activity <code>UNKNOWN</code>, because it was not present in train log.</p>"},{"location":"examples/#save-and-load-encoder-to-disk","title":"Save and load encoder to disk","text":"<p>You can save the encoder object to a file and load it for later use. In order to save an encoder to disk you need to freeze it first.</p> <p>The following example shows a simple save/load worflow.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.frequency_encoder import FrequencyEncoder\nfrom enc4ppm.constants import LabelingType\n\nlog = pd.read_csv('log.csv')\n\nencoder = FrequencyEncoder(\n    labeling_type=LabelingType.NEXT_ACTIVITY\n)\n\nencoded_log = encoder.encode(log, freeze=True)              # freeze encoder\nencoder.summary()                                           # print info about the encoder\n\nencoder.save('/path/to/encoder.pkl')                        # save encoder to disk\n\nloaded_encoder = BaseEncoder.load('/path/to/encoder.pkl')   # load encoder from disk\nloaded_encoder.summary()                                    # print info about loaded_encoder (should output the same as encoder.summary())\n\ninference_log = pd.read_csv('inference.csv')\nencoded_inference_log = loaded_encoder.encode(inference_log)\n</code></pre>"},{"location":"examples/#prefix-length-and-strategy","title":"Prefix length and strategy","text":"<p>You can specify <code>prefix_length</code> to set a specific prefix length, otherwise the maximum prefix length found in the log will be used. You can specify <code>prefix_strategy</code> to be either <code>up_to_specified</code> (the default) which will consider all prefix lengths from 1 up to <code>prefix_length</code>, or <code>only_specified</code> which will consider only prefix of length <code>prefix_length</code>.</p> <p>The following code encodes a log keeping only examples with a prefix length of 10.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.simple_index_encoder import SimpleIndexEncoder\nfrom enc4ppm.constants import LabelingType, PrefixStrategy\n\nlog = pd.read_csv('log.csv')\n\nencoder = SimpleIndexEncoder(\n    labeling_type=LabelingType.REMAINING_TIME,\n    prefix_length=10,\n    prefix_strategy=PrefixStrategy.ONLY_SPECIFIED,\n)\n\nencoded_log = encoder.encode(log)\n</code></pre>"},{"location":"examples/#categorical-encoding","title":"Categorical encoding","text":"<p>The <code>categorical_encoding</code> parameter determines whether categorical values (activity names and categorical attributes) are kept as <code>string</code> (default) or <code>one-hot</code> encoded.</p> <p>The following example encodes with one-hot encoding.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.simple_index_encoder import SimpleIndexEncoder\nfrom enc4ppm.constants import LabelingType, CategoricalEncoding\n\nlog = pd.read_csv('log.csv')\n\nencoder = SimpleIndexEncoder(\n    labeling_type=LabelingType.REMAINING_TIME,\n    categorical_encoding=CategoricalEncoding.ONE_HOT,\n)\n\nencoded_log = encoder.encode(log)\n</code></pre>"},{"location":"examples/#numerical-scaling","title":"Numerical scaling","text":"<p>The <code>numerical_scaling</code> parameter can be used to scale numerical values (numerical attributes, label in the case of remaining time, and TimeSinceCaseStart and TimeSincePreviousActivity features). It can be either <code>none</code> (default) to not apply any scaling, or <code>standardization</code> to apply standardization. The dictionary <code>encoder.numerical_scaling_info</code> will contain <code>mean</code> and <code>std</code> values to transform standardized numerical values back to their original range. <code>unscale_numerical_feature</code> is a helper method that unscales standardization automatically.</p> <p>The following example first standardizes all numerical values, then restores the 'label' column back to its original space.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.frequency_encoder import FrequencyEncoder\nfrom enc4ppm.constants import LabelingType, NumericalScaling\n\nlog = pd.read_csv('log.csv')\n\nencoder = FrequencyEncoder(\n    labeling_type=LabelingType.REMAINING_TIME,\n    numerical_scaling=NumericalScaling.STANDARDIZATION,\n)\n\nencoded_log = encoder.encode(log)\n\n# Use encoder.numerical_scaling_info to restore original label values...\nrestored_label = encoder.numerical_scaling_info[encoder.LABEL_KEY]['std'] * encoded_log[encoder.LABEL_KEY] + encoder.numerical_scaling_info[encoder.LABEL_KEY]['mean']\n\n# ... or use the method unscale_numerical_feature()\nrestored_label = encoder.unscale_numerical_feature(encoded_log[encoder.LABEL_KEY], encoder.LABEL_KEY)\n\n</code></pre>"},{"location":"examples/#label-remaining-time-as-a-classification-task","title":"Label remaining time as a classification task","text":"<p>Instead of labeling remaining time as a regression task (with label being the number of hours for remaining trace completion), it is also possible to label it as a classification task.</p> <p>The following example labels remaining time as a classification problem, also specifying the number of bins to divide times in.</p> <pre><code>import pandas as pd\n\nfrom enc4ppm.simple_index_encoder import SimpleIndexEncoder\nfrom enc4ppm.constants import LabelingType\n\nlog = pd.read_csv('log.csv')\n\nencoder = SimpleIndexEncoder(\n    labeling_type=LabelingType.REMAINING_TIME_CLASSIFICATION\n)\nencoder.set_remaining_time_num_bins(10) # cut in 10 bins (10 classes)\n\nencoded_log = encoder.encode(log)\n</code></pre>"},{"location":"reference/base_encoder/","title":"BaseEncoder Module API Reference","text":""},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder","title":"<code>BaseEncoder</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>class BaseEncoder(ABC):\n    ORIGINAL_INDEX_KEY = 'OriginalIndex'\n    TIME_SINCE_CS_KEY = 'TimeSinceCaseStart'\n    TIME_SINCE_PE_KEY = 'TimeSincePreviousEvent'\n    EVENT_COL_PREFIX_NAME = 'event'\n    TIMESTAMP_COL_PREFIX_NAME = 'Timestamp'\n    LATEST_PAYLOAD_COL_SUFFIX_NAME = 'latest'\n    LABEL_KEY = 'label'\n    UNKNOWN_VAL = 'UNKNOWN'\n    PADDING_CAT_VAL = 'PADDING'\n    PADDING_NUM_VAL = 0.0\n\n    def __init__(\n        self,\n        labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n        attributes: list[str] | str = [],\n        categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n        numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n        prefix_length: int = None,\n        prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n        add_time_features: bool = False,\n        timestamp_format: str = None,\n        case_id_key: str = 'case:concept:name',\n        activity_key: str = 'concept:name',\n        timestamp_key: str = 'time:timestamp',\n        outcome_key: str = 'outcome',\n    ) -&gt; None:\n        self.labeling_type = labeling_type\n        self.attributes = attributes\n        self.categorical_encoding = categorical_encoding\n        self.numerical_scaling = numerical_scaling\n        self.prefix_length = prefix_length\n        self.prefix_strategy = prefix_strategy\n        self.add_time_features = add_time_features\n        self.timestamp_format = timestamp_format\n        self.case_id_key = case_id_key\n        self.activity_key = activity_key\n        self.timestamp_key = timestamp_key\n        self.outcome_key = outcome_key\n\n        # Instance variables\n        self.is_frozen: bool = False\n        self.was_frozen: bool = False\n        self.original_df: pd.DataFrame = pd.DataFrame()\n        self.log_activities: list[str] = []\n        self.log_attributes: dict[str, dict[str, str | list | dict]] = {}\n        self.numerical_scaling_info = {}\n        self.remaining_time_num_bins = 10\n\n\n    @abstractmethod\n    def _encode(self, df: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:\n        \"\"\"\n        The _encode abstract method must be defined by subclasses and must contain the specific encoding logic of the encoder.\n        In particular, the _encode implementation must create the necessary columns for the specific encoding + add the ORIGINAL_INDEX_KEY column.\n        The _encode method must not filter rows (events), but instead return them all: the BaseEncoder will then _apply_prefix_strategy to filter them.\n        \"\"\"\n        pass\n\n\n    def _encode_template(self, df: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:\n        \"\"\"\n        The _encode_template method is a template method which performs both common operations shared amongs all encoders and the specific logic of each encoder.\n        In particular, common operations are: _preprocess_log, _label_log, _apply_prefix_strategy and _postprocess_log; specific encoding is performed by the _encode method.\n        \"\"\"\n        self.original_df = df\n        self.was_frozen = self.is_frozen\n\n        self._check_log(df)\n        self._check_parameters(df)\n        df = self._preprocess_log(df)\n\n        if not self.is_frozen:\n            self._extract_log_data(df)\n\n        if 'freeze' in kwargs and kwargs['freeze']:\n            self.is_frozen = True\n\n        encoded_df = self._encode(df)\n\n        encoded_df = self._after_encode(encoded_df)\n        encoded_df = self._label_log(encoded_df)\n        encoded_df = self._apply_prefix_strategy(encoded_df)\n        encoded_df = self._postprocess_log(encoded_df)\n\n        return encoded_df\n\n\n    def _check_log(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Checks and validations on input log.\n        \"\"\"\n        if not isinstance(df, pd.DataFrame):\n            raise TypeError(\"df must be a pandas DataFrame\")\n\n        if df.empty:\n            raise ValueError(\"df cannot be empty\")\n\n        for col in [self.case_id_key, self.activity_key, self.timestamp_key]:\n            if col not in df.columns:\n                raise ValueError(f\"df must contain column '{col}'\")\n\n\n    def _check_parameters(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"\n        Checks and validations on encoder parameters.\n        \"\"\"\n        # Labeling type\n        if not isinstance(self.labeling_type, LabelingType):\n            raise TypeError(f'labeling_type must be a valid LabelingType: {[e.name for e in LabelingType]}')\n\n        if self.labeling_type == LabelingType.OUTCOME and (self.outcome_key is None or self.outcome_key not in df.columns):\n            raise ValueError(\"If labeling_type is set to OUTCOME, then you must specify the outcome_key parameter and it must be present in the DataFrame\")\n\n        # Attributes\n        if not isinstance(self.attributes, str) and not isinstance(self.attributes, list):\n            raise ValueError(f'attributes must be either a list of strings or the string \"all\"')\n\n        if isinstance(self.attributes, str) and self.attributes != 'all':\n            raise ValueError(\"Since attributes is set to a string, then it must be set to the value 'all'. Otherwise, set it to a list of strings indicating the attributes you want to consider.\")\n\n        if isinstance(self.attributes, list):\n            for attribute in self.attributes:\n                if not isinstance(attribute, str):\n                    raise ValueError('Since attributes is a list, it must contain only string elements')\n\n                if attribute not in self.original_df.columns:\n                    raise ValueError(f\"attributes contains value '{attribute}', which cannot be found in the log\")\n\n        # Prefix length and strategy\n        if self.prefix_length is not None and (not isinstance(self.prefix_length, int) or self.prefix_length &lt;= 0):\n            raise ValueError(f'prefix_length must be either None or a positive integer ({self.prefix_length} has been provided instead)')\n\n        if self.prefix_length is None and self.prefix_strategy == PrefixStrategy.ONLY_SPECIFIED:\n            raise ValueError(f'If prefix strategy is set to ONLY_SPECIFIED, then you must specify the prefix_length parameter')\n\n        if not isinstance(self.prefix_strategy, PrefixStrategy):\n            raise TypeError(f'prefix_strategy must be a valid PrefixStrategy: {[e.name for e in PrefixStrategy]}')\n\n\n    def _preprocess_log(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Common preprocessing logic shared by all encoders.\n        \"\"\"\n        df = df.copy()\n\n        # Cast case id column to string\n        df[self.case_id_key] = df[self.case_id_key].astype(str)\n\n        # Cast timestamp column to datetime\n        df[self.timestamp_key] = pd.to_datetime(df[self.timestamp_key], format=self.timestamp_format)\n\n        # Change null values to UNKNOWN_VAL or 0, based on their type\n        fill_dict = {}\n\n        for col in df.select_dtypes(include=['object', 'category']).columns:\n            fill_dict[col] = self.UNKNOWN_VAL\n\n        for col in df.select_dtypes(include=['number']).columns:\n            fill_dict[col] = 0\n\n        df = df.fillna(fill_dict).infer_objects(copy=False)\n\n        return df\n\n\n    def _extract_log_data(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"\n        From log data, create necessary variables for later use (e.g: determines prefix length, build activity and attribute vocabs, etc.)\n        \"\"\"\n        # Set prefix length\n        max_prefix_length_log = df.groupby(self.case_id_key).size().max().item()\n\n        if self.prefix_length is None:\n            self.prefix_length = max_prefix_length_log\n\n        # Build activity vocab\n        self.log_activities = df[self.activity_key].unique().tolist() + [self.UNKNOWN_VAL] + [self.PADDING_CAT_VAL]\n\n        # Build outcome vocab\n        if self.labeling_type == LabelingType.OUTCOME:\n            self.log_outcomes = df[self.outcome_key].unique().tolist()\n\n        # Build attribute vocabs\n        if self.attributes == 'all':\n            self.attributes = [a for a in df.columns.tolist() if a not in [self.case_id_key, self.activity_key, self.timestamp_key]]\n\n        for attribute_name in self.attributes:\n            attribute_values = df[attribute_name].unique()\n\n            is_numeric = is_numeric_dtype(attribute_values)\n            is_static = df.groupby(self.case_id_key)[attribute_name].nunique().eq(1).all()\n\n            attribute_dict = {\n                'type': 'numerical' if is_numeric else 'categorical',\n                'scope': 'trace' if is_static else 'event',\n            }\n\n            if is_numeric_dtype(attribute_values):\n                attribute_dict['values'] = {\n                    'min': attribute_values.min().item(),\n                    'max': attribute_values.max().item(),\n                    'mean': attribute_values.mean().item(),\n                    'std': attribute_values.std().item() if len(attribute_values) &gt; 1 else 0.0,\n                }\n            else:\n                attribute_values = attribute_values[attribute_values != self.UNKNOWN_VAL] # remove UNKNOWN_VAL if present, because it'll be added anyway\n                attribute_dict['values'] = attribute_values.tolist() + [self.UNKNOWN_VAL] + [self.PADDING_CAT_VAL]\n\n            self.log_attributes[attribute_name] = attribute_dict\n\n\n    def _after_encode(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Common logic to execute right after encoding.\n        \"\"\"\n        # Check whether OriginalIndex is present\n        if self.ORIGINAL_INDEX_KEY not in df.columns:\n            raise ValueError(f'You must include {self.ORIGINAL_INDEX_KEY} column when implementing your own custom encoder!')\n\n        # Sort by case and timestamp\n        df = df.sort_values([self.case_id_key, self.timestamp_key], ascending=[True, True]).reset_index(drop=True)\n\n        # If requested, add columns TimeSinceCaseStart and TimeSincePreviousEvent to dataframe\n        if self.add_time_features:\n            first_timestamp_per_case = df.groupby(self.case_id_key)[self.timestamp_key].transform('min')\n\n            df[self.TIME_SINCE_CS_KEY] = (df[self.timestamp_key] - first_timestamp_per_case).dt.total_seconds()\n            df[self.TIME_SINCE_PE_KEY] = df.groupby(self.case_id_key)[self.timestamp_key].diff().dt.total_seconds()\n            df[self.TIME_SINCE_PE_KEY] = df[self.TIME_SINCE_PE_KEY].fillna(0)\n\n        return df\n\n\n    def _label_log(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Common logic shared by all encoders. The method labels the provided log with the provided LabelingType.\n        \"\"\"\n        if self.labeling_type == LabelingType.NEXT_ACTIVITY:\n            # Get the next ORIGINAL_INDEX_KEY per case\n            df['next_index'] = df.groupby(self.case_id_key)[self.ORIGINAL_INDEX_KEY].shift(-1)\n\n            # Map next_index to activity in original_df\n            df[self.LABEL_KEY] = df['next_index'].map(\n                lambda idx: self._get_activity_value(self.original_df.at[idx, self.activity_key]) if pd.notna(idx) else None\n            )\n\n            # Drop the helper column\n            df = df.drop(columns=['next_index'])\n\n        elif self.labeling_type == LabelingType.REMAINING_TIME or self.labeling_type == LabelingType.REMAINING_TIME_CLASSIFICATION:\n            # Get the last timestamp for each case\n            last_timestamp_per_case = df.groupby(self.case_id_key)[self.timestamp_key].transform('max')\n\n            # Compute remaining time in hours\n            df[self.LABEL_KEY] = (last_timestamp_per_case - df[self.timestamp_key]).dt.total_seconds() / 60 / 60\n\n            if self.labeling_type == LabelingType.REMAINING_TIME:\n                # Save mean and std for later use\n                if not self.was_frozen:\n                    self.numerical_scaling_info[self.LABEL_KEY] = {\n                        'mean': df[self.LABEL_KEY].mean(),\n                        'std': df[self.LABEL_KEY].std(ddof=0),\n                    }\n\n            if self.labeling_type == LabelingType.REMAINING_TIME_CLASSIFICATION:\n                # Cut in bins\n                if not self.was_frozen:\n                    df[self.LABEL_KEY], bins = pd.cut(\n                        df[self.LABEL_KEY],\n                        bins=self.remaining_time_num_bins,\n                        retbins=True,\n                        include_lowest=True,\n                        right=False,\n                        labels=[f'Bin_{i+1}' for i in range(self.remaining_time_num_bins)]\n                    )\n                    df[self.LABEL_KEY] = df[self.LABEL_KEY].astype(str)\n                    self.remaining_time_bins = bins\n                else:\n                    df[self.LABEL_KEY] = pd.cut(\n                        df[self.LABEL_KEY],\n                        bins=self.remaining_time_bins,\n                        include_lowest=True,\n                        right=False,\n                        labels=[f'Bin_{i+1}' for i in range(len(self.remaining_time_bins)-1)]\n                    )\n                    df[self.LABEL_KEY] = df[self.LABEL_KEY].cat.add_categories([self.UNKNOWN_VAL])\n                    df[self.LABEL_KEY] = df[self.LABEL_KEY].fillna(self.UNKNOWN_VAL)\n                    df[self.LABEL_KEY] = df[self.LABEL_KEY].astype(str)\n\n        elif self.labeling_type == LabelingType.OUTCOME:\n            # Get outcome for each case (from original_df)\n            df[self.LABEL_KEY] = df[self.ORIGINAL_INDEX_KEY].map(self.original_df[self.outcome_key])\n\n        return df\n\n\n    def _apply_prefix_strategy(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Common logic shared by all encoders. The method filters the log with respect to specified prefix_length value.\n        \"\"\"\n        # Compute event number in case (starting from 1)\n        df = df.sort_values([self.case_id_key, self.timestamp_key], ascending=[True, True]).reset_index(drop=True)\n        df['event_num_in_case'] = df.groupby(self.case_id_key).cumcount() + 1\n\n        if self.prefix_strategy == PrefixStrategy.UP_TO_SPECIFIED:\n            filtered_df = df[df['event_num_in_case'] &lt;= self.prefix_length]\n        elif self.prefix_strategy == PrefixStrategy.ONLY_SPECIFIED:\n            filtered_df = df[df['event_num_in_case'] == self.prefix_length]\n        else:\n            filtered_df = df\n\n        # Drop the helper column\n        filtered_df = filtered_df.drop(columns=['event_num_in_case'])\n\n        return filtered_df\n\n\n    def _postprocess_log(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Common postprocessing logic shared by all encoders. The method restores original ordering and drops unnecessary data.\n        \"\"\"\n        if self.add_time_features and not self.was_frozen:\n            self.numerical_scaling_info[self.TIME_SINCE_CS_KEY] = {\n                'mean': df[self.TIME_SINCE_CS_KEY].mean(),\n                'std': df[self.TIME_SINCE_CS_KEY].std(ddof=0),\n            }\n            self.numerical_scaling_info[self.TIME_SINCE_PE_KEY] = {\n                'mean': df[self.TIME_SINCE_PE_KEY].mean(),\n                'std': df[self.TIME_SINCE_PE_KEY].std(ddof=0),\n            }\n\n        # Scale time features\n        if self.add_time_features:\n            if self.numerical_scaling == NumericalScaling.STANDARDIZATION:\n                df[self.TIME_SINCE_CS_KEY] = (df[self.TIME_SINCE_CS_KEY] - self.numerical_scaling_info[self.TIME_SINCE_CS_KEY]['mean']) / self.numerical_scaling_info[self.TIME_SINCE_CS_KEY]['std']\n                df[self.TIME_SINCE_PE_KEY] = (df[self.TIME_SINCE_PE_KEY] - self.numerical_scaling_info[self.TIME_SINCE_PE_KEY]['mean']) / self.numerical_scaling_info[self.TIME_SINCE_PE_KEY]['std']\n\n        # Scale label if it is remaining time\n        if self.labeling_type == LabelingType.REMAINING_TIME:\n            if self.numerical_scaling == NumericalScaling.STANDARDIZATION:\n                df[self.LABEL_KEY] = (df[self.LABEL_KEY] - self.numerical_scaling_info[self.LABEL_KEY]['mean']) / self.numerical_scaling_info[self.LABEL_KEY]['std']\n\n        # Scale numerical attributes\n        for attribute_name, attribute_info in self.log_attributes.items():\n            if attribute_info['type'] == 'numerical':\n                if self.numerical_scaling == NumericalScaling.STANDARDIZATION:\n                    for col in df.columns:\n                        if attribute_name in col:\n                            df[col] = (df[col] - self.log_attributes[attribute_name]['values']['mean']) / self.log_attributes[attribute_name]['values']['std']\n\n        # Restore original ordering\n        df = df.sort_values(by=self.ORIGINAL_INDEX_KEY).reset_index(drop=True)\n\n        # Drop unnecessary data\n        df = df.drop(columns=[self.timestamp_key, self.ORIGINAL_INDEX_KEY])\n        if self.labeling_type != LabelingType.NONE:\n            df = df.dropna(subset=[self.LABEL_KEY]).reset_index(drop=True)\n\n        return df\n\n\n    def _include_latest_payload(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Add latest payload attributes to encoded DataFrame. \n        \"\"\"\n        if self.attributes == [] or self.attributes is None:\n            return df\n\n        if self.ORIGINAL_INDEX_KEY not in df.columns:\n            raise ValueError(f'You must include {self.ORIGINAL_INDEX_KEY} column into df before calling _include_latest_payload')\n\n        # Add latest payload of specified attributes to the dataframe\n        for attribute_name in self.attributes:\n            attribute_values = []\n\n            for _, row in df.iterrows():\n                attribute_values.append(\n                    self._get_attribute_value(attribute_name, self.original_df.loc[row[self.ORIGINAL_INDEX_KEY], attribute_name])\n                )\n\n            df[f'{attribute_name}_{self.LATEST_PAYLOAD_COL_SUFFIX_NAME}'] = attribute_values\n\n        return df\n\n\n    def _get_activity_value(self, activity_value: str) -&gt; str:\n        \"\"\"\n        Return specified activity_value if present in self.log_activities, otherwise a string representing unknown activity.\n        \"\"\"\n        if activity_value in self.log_activities:\n            return activity_value\n\n        return self.UNKNOWN_VAL\n\n\n    def _get_attribute_value(self, attribute_name: str, attribute_value: str) -&gt; str:\n        \"\"\"\n        Return specified attribute_value if present in self.log_attributes under attribute_name, otherwise a string representing unknown attribute.\n        \"\"\"\n        if attribute_name not in self.log_attributes:\n            raise ValueError(f'Attribute {attribute_name} not found in log attributes {list(self.log_attributes.keys())}')\n\n        # Numerical attribute\n        if self.log_attributes[attribute_name]['type'] == 'numerical':\n            return attribute_value\n\n        # Categorical attribute\n        if attribute_value in self.log_attributes[attribute_name]['values']:\n            return attribute_value\n\n        return self.UNKNOWN_VAL\n\n\n    def summary(self) -&gt; None:\n        \"\"\"\n        Print a summary of the encoder. Only works if the encoder has been frozen.\n        \"\"\"\n        if not self.is_frozen:\n            raise RuntimeError(\"Encoder must be frozen before summarizing.\")\n\n        # Print a summary of the encoder's configuration and learned parameters\n        print(\"Encoder Summary:\")\n        print(f\" - Encoder Type: {self.__class__.__name__}\")\n        print(f\" - Labeling Type: {self.labeling_type}\")\n        print(f\" - Categorical Encoding: {self.categorical_encoding}\")\n        print(f\" - Numerical Scaling Info: {self.numerical_scaling_info}\")\n        if self.labeling_type == LabelingType.REMAINING_TIME_CLASSIFICATION:\n            print(f\" - Remaining Time Num Bins: {self.remaining_time_num_bins}\")\n        print(f\" - Prefix Length: {self.prefix_length}\")\n        print(f\" - Prefix Strategy: {self.prefix_strategy}\")\n        print(f\" - Timestamp Format: {self.timestamp_format}\")\n        print(f\" - Case ID Key: {self.case_id_key}\")\n        print(f\" - Activity Key: {self.activity_key}\")\n        print(f\" - Timestamp Key: {self.timestamp_key}\")\n        print(f\" - Log Activities ({len(self.log_activities)}): {self.log_activities}\")\n        print(f\" - Log Attributes ({len(self.log_attributes)}):\")\n        pprint.pprint(self.log_attributes)\n\n\n    def save(self, filepath: str) -&gt; None:\n        \"\"\"\n        Save the encoder instance to a pickle file. Only works if the encoder has been frozen.\n\n        Args:\n            filepath (str): Path to the pickle file where the encoder will be saved.\n        \"\"\"\n        if not self.is_frozen:\n            raise RuntimeError(\"Encoder must be frozen before saving. Call with freeze=True during encoding.\")\n\n        # Do not save original_df\n        self.original_df = None\n\n        with open(filepath, 'wb') as f:\n            pickle.dump(self, f)\n\n\n    @classmethod\n    def load(cls, filepath: str):\n        \"\"\"\n        Load a frozen encoder instance from a pickle file.\n\n        Args:\n            filepath (str): Path to the pickle file to load.\n\n        Returns:\n            encoder (BaseEncoder): The loaded encoder instance.\n        \"\"\"\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(f\"File '{filepath}' does not exist.\")\n\n        with open(filepath, 'rb') as f:\n            encoder = pickle.load(f)\n\n        if not isinstance(encoder, cls):\n            raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n\n        return encoder\n\n\n    def unscale_numerical_feature(self, df: pd.DataFrame | pd.Series, feature_name: str) -&gt; pd.DataFrame | pd.Series:\n        \"\"\"\n        Reverts the scaling transformation applied to a numerical feature in a DataFrame or Series.\n\n        Args:\n            df (pd.DataFrame | pd.Series): The input data containing the scaled feature(s) to be unscaled.\n            feature_name (str): The name of the numerical feature to unscale.\n\n        Returns:\n            df (pd.DataFrame | pd.Series): The DataFrame or Series with the specified feature unscaled.\n        \"\"\"\n        if self.numerical_scaling_info is None or feature_name not in self.numerical_scaling_info:\n            raise ValueError(f'Feature {feature_name} has no scaling info available. Available scaling info: {self.numerical_scaling_info}')\n\n        df = df.copy()\n\n        if isinstance(df, pd.Series):\n            return df * self.numerical_scaling_info[feature_name]['std'] + self.numerical_scaling_info[feature_name]['mean']\n        elif isinstance(df, pd.DataFrame):\n            if feature_name not in df.columns:\n                raise ValueError(f'Feature {feature_name} not found in provided DataFrame. Available columns: {df.columns.tolist()}')\n\n            df[feature_name] = df[feature_name] * self.numerical_scaling_info[feature_name]['std'] + self.numerical_scaling_info[feature_name]['mean']\n\n        return df\n\n\n    def set_remaining_time_num_bins(self, num_bins: int) -&gt; None:\n        \"\"\"\n        Set the number of bins to use for remaining time classification. Only works if the encoder has not been frozen yet.\n\n        Args:\n            num_bins (int): Number of bins to use for remaining time classification.\n        \"\"\"\n        if self.is_frozen:\n            raise RuntimeError(\"Cannot change remaining time bins after encoder has been frozen.\")\n\n        if not isinstance(num_bins, int) or num_bins &lt;= 0:\n            raise ValueError(\"num_bins must be a positive integer.\")\n\n        self.remaining_time_num_bins = num_bins\n</code></pre>"},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder.load","title":"<code>load(filepath)</code>  <code>classmethod</code>","text":"<p>Load a frozen encoder instance from a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the pickle file to load.</p> required <p>Returns:</p> Name Type Description <code>encoder</code> <code>BaseEncoder</code> <p>The loaded encoder instance.</p> Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>@classmethod\ndef load(cls, filepath: str):\n    \"\"\"\n    Load a frozen encoder instance from a pickle file.\n\n    Args:\n        filepath (str): Path to the pickle file to load.\n\n    Returns:\n        encoder (BaseEncoder): The loaded encoder instance.\n    \"\"\"\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File '{filepath}' does not exist.\")\n\n    with open(filepath, 'rb') as f:\n        encoder = pickle.load(f)\n\n    if not isinstance(encoder, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n\n    return encoder\n</code></pre>"},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder.save","title":"<code>save(filepath)</code>","text":"<p>Save the encoder instance to a pickle file. Only works if the encoder has been frozen.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the pickle file where the encoder will be saved.</p> required Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>def save(self, filepath: str) -&gt; None:\n    \"\"\"\n    Save the encoder instance to a pickle file. Only works if the encoder has been frozen.\n\n    Args:\n        filepath (str): Path to the pickle file where the encoder will be saved.\n    \"\"\"\n    if not self.is_frozen:\n        raise RuntimeError(\"Encoder must be frozen before saving. Call with freeze=True during encoding.\")\n\n    # Do not save original_df\n    self.original_df = None\n\n    with open(filepath, 'wb') as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder.set_remaining_time_num_bins","title":"<code>set_remaining_time_num_bins(num_bins)</code>","text":"<p>Set the number of bins to use for remaining time classification. Only works if the encoder has not been frozen yet.</p> <p>Parameters:</p> Name Type Description Default <code>num_bins</code> <code>int</code> <p>Number of bins to use for remaining time classification.</p> required Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>def set_remaining_time_num_bins(self, num_bins: int) -&gt; None:\n    \"\"\"\n    Set the number of bins to use for remaining time classification. Only works if the encoder has not been frozen yet.\n\n    Args:\n        num_bins (int): Number of bins to use for remaining time classification.\n    \"\"\"\n    if self.is_frozen:\n        raise RuntimeError(\"Cannot change remaining time bins after encoder has been frozen.\")\n\n    if not isinstance(num_bins, int) or num_bins &lt;= 0:\n        raise ValueError(\"num_bins must be a positive integer.\")\n\n    self.remaining_time_num_bins = num_bins\n</code></pre>"},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder.summary","title":"<code>summary()</code>","text":"<p>Print a summary of the encoder. Only works if the encoder has been frozen.</p> Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>def summary(self) -&gt; None:\n    \"\"\"\n    Print a summary of the encoder. Only works if the encoder has been frozen.\n    \"\"\"\n    if not self.is_frozen:\n        raise RuntimeError(\"Encoder must be frozen before summarizing.\")\n\n    # Print a summary of the encoder's configuration and learned parameters\n    print(\"Encoder Summary:\")\n    print(f\" - Encoder Type: {self.__class__.__name__}\")\n    print(f\" - Labeling Type: {self.labeling_type}\")\n    print(f\" - Categorical Encoding: {self.categorical_encoding}\")\n    print(f\" - Numerical Scaling Info: {self.numerical_scaling_info}\")\n    if self.labeling_type == LabelingType.REMAINING_TIME_CLASSIFICATION:\n        print(f\" - Remaining Time Num Bins: {self.remaining_time_num_bins}\")\n    print(f\" - Prefix Length: {self.prefix_length}\")\n    print(f\" - Prefix Strategy: {self.prefix_strategy}\")\n    print(f\" - Timestamp Format: {self.timestamp_format}\")\n    print(f\" - Case ID Key: {self.case_id_key}\")\n    print(f\" - Activity Key: {self.activity_key}\")\n    print(f\" - Timestamp Key: {self.timestamp_key}\")\n    print(f\" - Log Activities ({len(self.log_activities)}): {self.log_activities}\")\n    print(f\" - Log Attributes ({len(self.log_attributes)}):\")\n    pprint.pprint(self.log_attributes)\n</code></pre>"},{"location":"reference/base_encoder/#enc4ppm.base_encoder.BaseEncoder.unscale_numerical_feature","title":"<code>unscale_numerical_feature(df, feature_name)</code>","text":"<p>Reverts the scaling transformation applied to a numerical feature in a DataFrame or Series.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame | Series</code> <p>The input data containing the scaled feature(s) to be unscaled.</p> required <code>feature_name</code> <code>str</code> <p>The name of the numerical feature to unscale.</p> required <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame | Series</code> <p>The DataFrame or Series with the specified feature unscaled.</p> Source code in <code>src/enc4ppm/base_encoder.py</code> <pre><code>def unscale_numerical_feature(self, df: pd.DataFrame | pd.Series, feature_name: str) -&gt; pd.DataFrame | pd.Series:\n    \"\"\"\n    Reverts the scaling transformation applied to a numerical feature in a DataFrame or Series.\n\n    Args:\n        df (pd.DataFrame | pd.Series): The input data containing the scaled feature(s) to be unscaled.\n        feature_name (str): The name of the numerical feature to unscale.\n\n    Returns:\n        df (pd.DataFrame | pd.Series): The DataFrame or Series with the specified feature unscaled.\n    \"\"\"\n    if self.numerical_scaling_info is None or feature_name not in self.numerical_scaling_info:\n        raise ValueError(f'Feature {feature_name} has no scaling info available. Available scaling info: {self.numerical_scaling_info}')\n\n    df = df.copy()\n\n    if isinstance(df, pd.Series):\n        return df * self.numerical_scaling_info[feature_name]['std'] + self.numerical_scaling_info[feature_name]['mean']\n    elif isinstance(df, pd.DataFrame):\n        if feature_name not in df.columns:\n            raise ValueError(f'Feature {feature_name} not found in provided DataFrame. Available columns: {df.columns.tolist()}')\n\n        df[feature_name] = df[feature_name] * self.numerical_scaling_info[feature_name]['std'] + self.numerical_scaling_info[feature_name]['mean']\n\n    return df\n</code></pre>"},{"location":"reference/complex_index_encoder/","title":"ComplexIndexEncoder Module API Reference","text":""},{"location":"reference/complex_index_encoder/#enc4ppm.complex_index_encoder.ComplexIndexEncoder","title":"<code>ComplexIndexEncoder</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>src/enc4ppm/complex_index_encoder.py</code> <pre><code>class ComplexIndexEncoder(BaseEncoder):\n    def __init__(\n        self,\n        include_timestamps: bool = False,\n        *,\n        labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n        attributes: list[str] | str = [],\n        categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n        numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n        prefix_length: int = None,\n        prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n        add_time_features: bool = False,\n        timestamp_format: str = None,\n        case_id_key: str = 'case:concept:name',\n        activity_key: str = 'concept:name',\n        timestamp_key: str = 'time:timestamp',\n        outcome_key: str = 'outcome',\n    ) -&gt; None:\n        \"\"\"\n        Initialize the ComplexIndexEncoder.\n\n        Args:\n            include_timestamps: Whether to add Timestamp columns or not.\n            labeling_type: Label type to apply to examples.\n            attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n            categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n            numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n            prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n            prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n            add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n            timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n            case_id_key: Column name for case identifiers.\n            activity_key: Column name for activity names.\n            timestamp_key: Column name for timestamps.\n            outcome_key: Column name for outcome predition.\n        \"\"\"\n        super().__init__(\n            labeling_type,\n            attributes,\n            categorical_encoding,\n            numerical_scaling,\n            prefix_length,\n            prefix_strategy,\n            add_time_features,\n            timestamp_format,\n            case_id_key,\n            activity_key,\n            timestamp_key,\n            outcome_key,\n        )\n\n        self.include_timestamps = include_timestamps\n\n\n    def encode(\n        self,\n        df: pd.DataFrame,\n        *,\n        freeze: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Encode the provided DataFrame with complex-index encoding and apply the specified labeling.\n\n        Args:\n            df: DataFrame to encode.\n            freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n        Returns:\n            The encoded DataFrame.\n        \"\"\"\n        return super()._encode_template(df, freeze=freeze)\n\n\n    def _encode(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        rows = []\n        grouped = df.groupby(self.case_id_key)\n\n        for case_id, case_events in grouped:\n            case_events = case_events.sort_values(self.timestamp_key).reset_index()\n\n            for prefix_length in range(1, len(case_events)+1):\n                row = {\n                    self.case_id_key: case_id,\n                    self.timestamp_key: case_events.loc[prefix_length-1, self.timestamp_key],\n                    self.ORIGINAL_INDEX_KEY: case_events.loc[prefix_length-1, 'index'],\n                }\n\n                # Add trace attributes\n                for attribute_name, attribute in self.log_attributes.items():\n                    if attribute['scope'] != 'trace': continue\n\n                    row[attribute_name] = self._get_attribute_value(attribute_name, case_events.loc[prefix_length-1, attribute_name])\n\n                # Add activities\n                for i in range(1, self.prefix_length+1):\n                    if i &lt;= prefix_length:\n                        row[f'{self.EVENT_COL_PREFIX_NAME}_{i}'] = self._get_activity_value(case_events.loc[i-1, self.activity_key])\n                    else:\n                        row[f'{self.EVENT_COL_PREFIX_NAME}_{i}'] = self.PADDING_CAT_VAL\n\n                # Add timestamps\n                if self.include_timestamps:\n                    for i in range(1, self.prefix_length+1):\n                        if i &lt;= prefix_length:\n                            row[f'{self.TIMESTAMP_COL_PREFIX_NAME}_{i}'] = case_events.loc[i-1, self.timestamp_key]\n                        else:\n                            row[f'{self.TIMESTAMP_COL_PREFIX_NAME}_{i}'] = pd.NaT\n\n                # Add event attributes\n                for attribute_name, attribute in self.log_attributes.items():\n                    if attribute['scope'] != 'event': continue\n\n                    for i in range(1, self.prefix_length+1):\n                        if i &lt;= prefix_length:\n                            row[f'{attribute_name}_{i}'] = self._get_attribute_value(attribute_name, case_events.loc[i-1, attribute_name])\n                        else:\n                            if attribute['type'] == 'categorical':\n                                row[f'{attribute_name}_{i}'] = self.PADDING_CAT_VAL\n                            else:\n                                row[f'{attribute_name}_{i}'] = self.PADDING_NUM_VAL\n\n                rows.append(row)\n\n        encoded_df = pd.DataFrame(rows)\n\n        # Transform to one-hot if requested\n        if self.categorical_encoding == CategoricalEncoding.ONE_HOT:\n            categorical_columns = []\n            categorical_columns_possible_values = []\n\n            # Activity columns\n            for i in range(1, self.prefix_length+1):\n                categorical_columns.append(f'{self.EVENT_COL_PREFIX_NAME}_{i}')\n                categorical_columns_possible_values.append(self.log_activities)\n\n            # Categorical attributes columns\n            for attribute_name, attribute in self.log_attributes.items():\n                if attribute['type'] == 'categorical':\n                    if attribute['scope'] == 'event':\n                        for i in range(1, self.prefix_length+1):\n                            categorical_columns.append(f'{attribute_name}_{i}')\n                            categorical_columns_possible_values.append(attribute['values'])\n                    else:\n                        # For trace attributes do not consider PADDING value\n                        attribute_possible_values = [attribute_value for attribute_value in attribute['values'] if attribute_value != self.PADDING_CAT_VAL]\n\n                        categorical_columns.append(attribute_name)\n                        categorical_columns_possible_values.append(attribute_possible_values)\n\n            encoded_df = one_hot(\n                encoded_df,\n                columns=categorical_columns,\n                columns_possible_values=categorical_columns_possible_values,\n                unknown_value=self.UNKNOWN_VAL,\n            )\n\n        return encoded_df\n</code></pre>"},{"location":"reference/complex_index_encoder/#enc4ppm.complex_index_encoder.ComplexIndexEncoder.__init__","title":"<code>__init__(include_timestamps=False, *, labeling_type=LabelingType.NEXT_ACTIVITY, attributes=[], categorical_encoding=CategoricalEncoding.STRING, numerical_scaling=NumericalScaling.NONE, prefix_length=None, prefix_strategy=PrefixStrategy.UP_TO_SPECIFIED, add_time_features=False, timestamp_format=None, case_id_key='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp', outcome_key='outcome')</code>","text":"<p>Initialize the ComplexIndexEncoder.</p> <p>Parameters:</p> Name Type Description Default <code>include_timestamps</code> <code>bool</code> <p>Whether to add Timestamp columns or not.</p> <code>False</code> <code>labeling_type</code> <code>LabelingType</code> <p>Label type to apply to examples.</p> <code>NEXT_ACTIVITY</code> <code>attributes</code> <code>list[str] | str</code> <p>Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).</p> <code>[]</code> <code>categorical_encoding</code> <code>CategoricalEncoding</code> <p>How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).</p> <code>STRING</code> <code>numerical_scaling</code> <code>NumericalScaling</code> <p>How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).</p> <code>NONE</code> <code>prefix_length</code> <code>int</code> <p>Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.</p> <code>None</code> <code>prefix_strategy</code> <code>PrefixStrategy</code> <p>Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).</p> <code>UP_TO_SPECIFIED</code> <code>add_time_features</code> <code>bool</code> <p>Whether to add time features (time since case start and time since last event) to the encoding.</p> <code>False</code> <code>timestamp_format</code> <code>str</code> <p>Format of the timestamps in the log. If not provided, formatting will be inferred from the data.</p> <code>None</code> <code>case_id_key</code> <code>str</code> <p>Column name for case identifiers.</p> <code>'case:concept:name'</code> <code>activity_key</code> <code>str</code> <p>Column name for activity names.</p> <code>'concept:name'</code> <code>timestamp_key</code> <code>str</code> <p>Column name for timestamps.</p> <code>'time:timestamp'</code> <code>outcome_key</code> <code>str</code> <p>Column name for outcome predition.</p> <code>'outcome'</code> Source code in <code>src/enc4ppm/complex_index_encoder.py</code> <pre><code>def __init__(\n    self,\n    include_timestamps: bool = False,\n    *,\n    labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n    attributes: list[str] | str = [],\n    categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n    numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n    prefix_length: int = None,\n    prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n    add_time_features: bool = False,\n    timestamp_format: str = None,\n    case_id_key: str = 'case:concept:name',\n    activity_key: str = 'concept:name',\n    timestamp_key: str = 'time:timestamp',\n    outcome_key: str = 'outcome',\n) -&gt; None:\n    \"\"\"\n    Initialize the ComplexIndexEncoder.\n\n    Args:\n        include_timestamps: Whether to add Timestamp columns or not.\n        labeling_type: Label type to apply to examples.\n        attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n        categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n        numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n        prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n        prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n        add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n        timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n        case_id_key: Column name for case identifiers.\n        activity_key: Column name for activity names.\n        timestamp_key: Column name for timestamps.\n        outcome_key: Column name for outcome predition.\n    \"\"\"\n    super().__init__(\n        labeling_type,\n        attributes,\n        categorical_encoding,\n        numerical_scaling,\n        prefix_length,\n        prefix_strategy,\n        add_time_features,\n        timestamp_format,\n        case_id_key,\n        activity_key,\n        timestamp_key,\n        outcome_key,\n    )\n\n    self.include_timestamps = include_timestamps\n</code></pre>"},{"location":"reference/complex_index_encoder/#enc4ppm.complex_index_encoder.ComplexIndexEncoder.encode","title":"<code>encode(df, *, freeze=False)</code>","text":"<p>Encode the provided DataFrame with complex-index encoding and apply the specified labeling.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to encode.</p> required <code>freeze</code> <code>bool</code> <p>Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The encoded DataFrame.</p> Source code in <code>src/enc4ppm/complex_index_encoder.py</code> <pre><code>def encode(\n    self,\n    df: pd.DataFrame,\n    *,\n    freeze: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Encode the provided DataFrame with complex-index encoding and apply the specified labeling.\n\n    Args:\n        df: DataFrame to encode.\n        freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n    Returns:\n        The encoded DataFrame.\n    \"\"\"\n    return super()._encode_template(df, freeze=freeze)\n</code></pre>"},{"location":"reference/frequency_encoder/","title":"FrequencyEncoder Module API Reference","text":""},{"location":"reference/frequency_encoder/#enc4ppm.frequency_encoder.FrequencyEncoder","title":"<code>FrequencyEncoder</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>src/enc4ppm/frequency_encoder.py</code> <pre><code>class FrequencyEncoder(BaseEncoder):\n    def __init__(\n        self,\n        *,\n        include_latest_payload: bool = False,\n\n        labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n        attributes: list[str] | str = [],\n        categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n        numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n        prefix_length: int = None,\n        prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n        add_time_features: bool = False,\n        timestamp_format: str = None,\n        case_id_key: str = 'case:concept:name',\n        activity_key: str = 'concept:name',\n        timestamp_key: str = 'time:timestamp',\n        outcome_key: str = 'outcome',\n    ) -&gt; None:\n        \"\"\"\n        Initialize the FrequencyEncoder.\n\n        Args:\n            include_latest_payload: Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the `attributes` parameter.\n            labeling_type: Label type to apply to examples.\n            attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n            categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n            numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n            prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n            prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n            add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n            timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n            case_id_key: Column name for case identifiers.\n            activity_key: Column name for activity names.\n            timestamp_key: Column name for timestamps.\n            outcome_key: Column name for outcome predition.\n        \"\"\"\n        super().__init__(\n            labeling_type,\n            attributes,\n            categorical_encoding,\n            numerical_scaling,\n            prefix_length,\n            prefix_strategy,\n            add_time_features,\n            timestamp_format,\n            case_id_key,\n            activity_key,\n            timestamp_key,\n            outcome_key,\n        )\n\n        self.include_latest_payload = include_latest_payload\n\n\n    def encode(\n        self,\n        df: pd.DataFrame,\n        *,\n        freeze: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Encode the provided DataFrame with frequency encoding and apply the specified labeling.\n\n        Args:\n            df: DataFrame to encode.\n            freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n        Returns:\n            The encoded DataFrame.\n        \"\"\"\n        return super()._encode_template(df, freeze=freeze)\n\n\n    def _encode(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        rows = []\n        grouped = df.groupby(self.case_id_key)\n\n        for case_id, case_events in grouped:\n            case_events = case_events.sort_values(self.timestamp_key)\n\n            for prefix_length in range(1, len(case_events)+1):\n                prefix = case_events.iloc[:prefix_length]\n                counts = prefix[self.activity_key].value_counts()\n\n                row = {\n                    self.case_id_key: case_id,\n                    self.timestamp_key: prefix.iloc[-1][self.timestamp_key],\n                    self.ORIGINAL_INDEX_KEY: prefix.index[-1],\n                }\n\n                for activity in self.log_activities[:-1]:\n                    row[activity] = counts.get(activity, 0)\n\n                # Handle unknown activities\n                row[self.UNKNOWN_VAL] = sum(counts.get(activity, 0) for activity in counts.index if activity not in self.log_activities[:-1])\n\n                rows.append(row)\n\n        encoded_df = pd.DataFrame(rows)\n\n        if self.include_latest_payload:\n            encoded_df = super()._include_latest_payload(encoded_df)\n\n        # Transform to one-hot if requested\n        if self.categorical_encoding == CategoricalEncoding.ONE_HOT:\n            categorical_columns = []\n            categorical_columns_possible_values = []\n\n            if self.include_latest_payload:\n                for attribute_name, attribute in self.log_attributes.items():\n                    if attribute['type'] == 'categorical':\n                        # For latest payload do not consider PADDING value\n                        attribute_possible_values = [attribute_value for attribute_value in attribute['values'] if attribute_value != self.PADDING_CAT_VAL]\n\n                        categorical_columns.append(f'{attribute_name}_{self.LATEST_PAYLOAD_COL_SUFFIX_NAME}')\n                        categorical_columns_possible_values.append(attribute_possible_values)\n\n            encoded_df = one_hot(\n                encoded_df,\n                columns=categorical_columns,\n                columns_possible_values=categorical_columns_possible_values,\n                unknown_value=self.UNKNOWN_VAL,\n            )\n\n        return encoded_df\n</code></pre>"},{"location":"reference/frequency_encoder/#enc4ppm.frequency_encoder.FrequencyEncoder.__init__","title":"<code>__init__(*, include_latest_payload=False, labeling_type=LabelingType.NEXT_ACTIVITY, attributes=[], categorical_encoding=CategoricalEncoding.STRING, numerical_scaling=NumericalScaling.NONE, prefix_length=None, prefix_strategy=PrefixStrategy.UP_TO_SPECIFIED, add_time_features=False, timestamp_format=None, case_id_key='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp', outcome_key='outcome')</code>","text":"<p>Initialize the FrequencyEncoder.</p> <p>Parameters:</p> Name Type Description Default <code>include_latest_payload</code> <code>bool</code> <p>Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the <code>attributes</code> parameter.</p> <code>False</code> <code>labeling_type</code> <code>LabelingType</code> <p>Label type to apply to examples.</p> <code>NEXT_ACTIVITY</code> <code>attributes</code> <code>list[str] | str</code> <p>Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).</p> <code>[]</code> <code>categorical_encoding</code> <code>CategoricalEncoding</code> <p>How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).</p> <code>STRING</code> <code>numerical_scaling</code> <code>NumericalScaling</code> <p>How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).</p> <code>NONE</code> <code>prefix_length</code> <code>int</code> <p>Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.</p> <code>None</code> <code>prefix_strategy</code> <code>PrefixStrategy</code> <p>Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).</p> <code>UP_TO_SPECIFIED</code> <code>add_time_features</code> <code>bool</code> <p>Whether to add time features (time since case start and time since last event) to the encoding.</p> <code>False</code> <code>timestamp_format</code> <code>str</code> <p>Format of the timestamps in the log. If not provided, formatting will be inferred from the data.</p> <code>None</code> <code>case_id_key</code> <code>str</code> <p>Column name for case identifiers.</p> <code>'case:concept:name'</code> <code>activity_key</code> <code>str</code> <p>Column name for activity names.</p> <code>'concept:name'</code> <code>timestamp_key</code> <code>str</code> <p>Column name for timestamps.</p> <code>'time:timestamp'</code> <code>outcome_key</code> <code>str</code> <p>Column name for outcome predition.</p> <code>'outcome'</code> Source code in <code>src/enc4ppm/frequency_encoder.py</code> <pre><code>def __init__(\n    self,\n    *,\n    include_latest_payload: bool = False,\n\n    labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n    attributes: list[str] | str = [],\n    categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n    numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n    prefix_length: int = None,\n    prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n    add_time_features: bool = False,\n    timestamp_format: str = None,\n    case_id_key: str = 'case:concept:name',\n    activity_key: str = 'concept:name',\n    timestamp_key: str = 'time:timestamp',\n    outcome_key: str = 'outcome',\n) -&gt; None:\n    \"\"\"\n    Initialize the FrequencyEncoder.\n\n    Args:\n        include_latest_payload: Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the `attributes` parameter.\n        labeling_type: Label type to apply to examples.\n        attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n        categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n        numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n        prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n        prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n        add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n        timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n        case_id_key: Column name for case identifiers.\n        activity_key: Column name for activity names.\n        timestamp_key: Column name for timestamps.\n        outcome_key: Column name for outcome predition.\n    \"\"\"\n    super().__init__(\n        labeling_type,\n        attributes,\n        categorical_encoding,\n        numerical_scaling,\n        prefix_length,\n        prefix_strategy,\n        add_time_features,\n        timestamp_format,\n        case_id_key,\n        activity_key,\n        timestamp_key,\n        outcome_key,\n    )\n\n    self.include_latest_payload = include_latest_payload\n</code></pre>"},{"location":"reference/frequency_encoder/#enc4ppm.frequency_encoder.FrequencyEncoder.encode","title":"<code>encode(df, *, freeze=False)</code>","text":"<p>Encode the provided DataFrame with frequency encoding and apply the specified labeling.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to encode.</p> required <code>freeze</code> <code>bool</code> <p>Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The encoded DataFrame.</p> Source code in <code>src/enc4ppm/frequency_encoder.py</code> <pre><code>def encode(\n    self,\n    df: pd.DataFrame,\n    *,\n    freeze: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Encode the provided DataFrame with frequency encoding and apply the specified labeling.\n\n    Args:\n        df: DataFrame to encode.\n        freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n    Returns:\n        The encoded DataFrame.\n    \"\"\"\n    return super()._encode_template(df, freeze=freeze)\n</code></pre>"},{"location":"reference/simple_index_encoder/","title":"SimpleIndexEncoder Module API Reference","text":""},{"location":"reference/simple_index_encoder/#enc4ppm.simple_index_encoder.SimpleIndexEncoder","title":"<code>SimpleIndexEncoder</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>src/enc4ppm/simple_index_encoder.py</code> <pre><code>class SimpleIndexEncoder(BaseEncoder):\n    def __init__(\n        self,\n        *,\n        include_latest_payload: bool = False,\n\n        labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n        attributes: list[str] | str = [],\n        categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n        numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n        prefix_length: int = None,\n        prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n        add_time_features: bool = False,\n        timestamp_format: str = None,\n        case_id_key: str = 'case:concept:name',\n        activity_key: str = 'concept:name',\n        timestamp_key: str = 'time:timestamp',\n        outcome_key: str = 'outcome',\n    ) -&gt; None:\n        \"\"\"\n        Initialize the SimpleIndexEncoder.\n\n        Args:\n            include_latest_payload: Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the `attributes` parameter.\n            labeling_type: Label type to apply to examples.\n            attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n            categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n            numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n            prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n            prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n            add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n            timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n            case_id_key: Column name for case identifiers.\n            activity_key: Column name for activity names.\n            timestamp_key: Column name for timestamps.\n            outcome_key: Column name for outcome predition.\n        \"\"\"\n        super().__init__(\n            labeling_type,\n            attributes,\n            categorical_encoding,\n            numerical_scaling,\n            prefix_length,\n            prefix_strategy,\n            add_time_features,\n            timestamp_format,\n            case_id_key,\n            activity_key,\n            timestamp_key,\n            outcome_key,\n        )\n\n        self.include_latest_payload = include_latest_payload\n\n\n    def encode(\n        self,\n        df: pd.DataFrame,\n        *,\n        freeze: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Encode the provided DataFrame with simple-index encoding and apply the specified labeling.\n\n        Args:\n            df: DataFrame to encode.\n            freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n        Returns:\n            The encoded DataFrame.\n        \"\"\"\n        return super()._encode_template(df, freeze=freeze)\n\n\n    def _encode(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        rows = []\n        grouped = df.groupby(self.case_id_key)\n\n        for case_id, case_events in grouped:\n            case_events = case_events.sort_values(self.timestamp_key).reset_index()\n\n            for prefix_length in range(1, len(case_events)+1):\n                row = {\n                    self.case_id_key: case_id,\n                    self.timestamp_key: case_events.loc[prefix_length-1, self.timestamp_key],\n                    self.ORIGINAL_INDEX_KEY: case_events.loc[prefix_length-1, 'index'],\n                }\n\n                for i in range(1, self.prefix_length+1):\n                    if i &lt;= prefix_length:\n                        row[f'{self.EVENT_COL_PREFIX_NAME}_{i}'] = self._get_activity_value(case_events.loc[i-1, self.activity_key])\n                    else:\n                        row[f'{self.EVENT_COL_PREFIX_NAME}_{i}'] = self.PADDING_CAT_VAL\n\n                rows.append(row)\n\n        encoded_df = pd.DataFrame(rows)\n\n        if self.include_latest_payload:\n            encoded_df = super()._include_latest_payload(encoded_df)\n\n        # Transform to one-hot if requested\n        if self.categorical_encoding == CategoricalEncoding.ONE_HOT:\n            categorical_columns = []\n            categorical_columns_possible_values = []\n\n            # Activity columns\n            for i in range(1, self.prefix_length+1):\n                categorical_columns.append(f'{self.EVENT_COL_PREFIX_NAME}_{i}')\n                categorical_columns_possible_values.append(self.log_activities)\n\n            # Latest payload columns\n            if self.include_latest_payload:\n                for attribute_name, attribute in self.log_attributes.items():\n                    if attribute['type'] == 'categorical':\n                        # For latest payload do not consider PADDING value\n                        attribute_possible_values = [attribute_value for attribute_value in attribute['values'] if attribute_value != self.PADDING_CAT_VAL]\n\n                        categorical_columns.append(f'{attribute_name}_{self.LATEST_PAYLOAD_COL_SUFFIX_NAME}')\n                        categorical_columns_possible_values.append(attribute_possible_values)\n\n            encoded_df = one_hot(\n                encoded_df,\n                columns=categorical_columns,\n                columns_possible_values=categorical_columns_possible_values,\n                unknown_value=self.UNKNOWN_VAL,\n            )\n\n        return encoded_df\n</code></pre>"},{"location":"reference/simple_index_encoder/#enc4ppm.simple_index_encoder.SimpleIndexEncoder.__init__","title":"<code>__init__(*, include_latest_payload=False, labeling_type=LabelingType.NEXT_ACTIVITY, attributes=[], categorical_encoding=CategoricalEncoding.STRING, numerical_scaling=NumericalScaling.NONE, prefix_length=None, prefix_strategy=PrefixStrategy.UP_TO_SPECIFIED, add_time_features=False, timestamp_format=None, case_id_key='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp', outcome_key='outcome')</code>","text":"<p>Initialize the SimpleIndexEncoder.</p> <p>Parameters:</p> Name Type Description Default <code>include_latest_payload</code> <code>bool</code> <p>Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the <code>attributes</code> parameter.</p> <code>False</code> <code>labeling_type</code> <code>LabelingType</code> <p>Label type to apply to examples.</p> <code>NEXT_ACTIVITY</code> <code>attributes</code> <code>list[str] | str</code> <p>Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).</p> <code>[]</code> <code>categorical_encoding</code> <code>CategoricalEncoding</code> <p>How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).</p> <code>STRING</code> <code>numerical_scaling</code> <code>NumericalScaling</code> <p>How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).</p> <code>NONE</code> <code>prefix_length</code> <code>int</code> <p>Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.</p> <code>None</code> <code>prefix_strategy</code> <code>PrefixStrategy</code> <p>Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).</p> <code>UP_TO_SPECIFIED</code> <code>add_time_features</code> <code>bool</code> <p>Whether to add time features (time since case start and time since last event) to the encoding.</p> <code>False</code> <code>timestamp_format</code> <code>str</code> <p>Format of the timestamps in the log. If not provided, formatting will be inferred from the data.</p> <code>None</code> <code>case_id_key</code> <code>str</code> <p>Column name for case identifiers.</p> <code>'case:concept:name'</code> <code>activity_key</code> <code>str</code> <p>Column name for activity names.</p> <code>'concept:name'</code> <code>timestamp_key</code> <code>str</code> <p>Column name for timestamps.</p> <code>'time:timestamp'</code> <code>outcome_key</code> <code>str</code> <p>Column name for outcome predition.</p> <code>'outcome'</code> Source code in <code>src/enc4ppm/simple_index_encoder.py</code> <pre><code>def __init__(\n    self,\n    *,\n    include_latest_payload: bool = False,\n\n    labeling_type: LabelingType = LabelingType.NEXT_ACTIVITY,\n    attributes: list[str] | str = [],\n    categorical_encoding: CategoricalEncoding = CategoricalEncoding.STRING,\n    numerical_scaling: NumericalScaling = NumericalScaling.NONE,\n    prefix_length: int = None,\n    prefix_strategy: PrefixStrategy = PrefixStrategy.UP_TO_SPECIFIED,\n    add_time_features: bool = False,\n    timestamp_format: str = None,\n    case_id_key: str = 'case:concept:name',\n    activity_key: str = 'concept:name',\n    timestamp_key: str = 'time:timestamp',\n    outcome_key: str = 'outcome',\n) -&gt; None:\n    \"\"\"\n    Initialize the SimpleIndexEncoder.\n\n    Args:\n        include_latest_payload: Whether to include (True) or not (False) the latest values of trace and event attributes. The attributes to consider can be specified through the `attributes` parameter.\n        labeling_type: Label type to apply to examples.\n        attributes: Which attributes to consider. Can be a list of the attributes to consider or the string 'all' (all attributes found in the log will be encoded).\n        categorical_encoding: How to encode categorical features. They can either remain strings (CategoricalEncoding.STRING) or be converted to one-hot vectors splitted across multiple columns (CategoricalEncoding.ONE_HOT).\n        numerical_scaling: How to scale numerical features. They can be standardized (NumericalScaling.STANDARDIZATION) or left as-is (NumericalScaling.NONE).\n        prefix_length: Maximum prefix length to consider: longer prefixes will be discarded, shorter prefixes may be discarded depending on prefix_strategy parameter. If not provided, defaults to maximum prefix length found in log. If provided, it must be a non-zero positive int number.\n        prefix_strategy: Whether to consider prefix lengths from 1 to prefix_length (PrefixStrategy.UP_TO_SPECIFIED) or only the specified prefix_length (PrefixStrategy.ONLY_SPECIFIED).\n        add_time_features: Whether to add time features (time since case start and time since last event) to the encoding.\n        timestamp_format: Format of the timestamps in the log. If not provided, formatting will be inferred from the data.\n        case_id_key: Column name for case identifiers.\n        activity_key: Column name for activity names.\n        timestamp_key: Column name for timestamps.\n        outcome_key: Column name for outcome predition.\n    \"\"\"\n    super().__init__(\n        labeling_type,\n        attributes,\n        categorical_encoding,\n        numerical_scaling,\n        prefix_length,\n        prefix_strategy,\n        add_time_features,\n        timestamp_format,\n        case_id_key,\n        activity_key,\n        timestamp_key,\n        outcome_key,\n    )\n\n    self.include_latest_payload = include_latest_payload\n</code></pre>"},{"location":"reference/simple_index_encoder/#enc4ppm.simple_index_encoder.SimpleIndexEncoder.encode","title":"<code>encode(df, *, freeze=False)</code>","text":"<p>Encode the provided DataFrame with simple-index encoding and apply the specified labeling.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to encode.</p> required <code>freeze</code> <code>bool</code> <p>Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The encoded DataFrame.</p> Source code in <code>src/enc4ppm/simple_index_encoder.py</code> <pre><code>def encode(\n    self,\n    df: pd.DataFrame,\n    *,\n    freeze: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Encode the provided DataFrame with simple-index encoding and apply the specified labeling.\n\n    Args:\n        df: DataFrame to encode.\n        freeze: Freeze encoder with provided parameters. Usually set to True when encoding the train log, False otherwise. Required if you want to later save the encoder to a file.\n\n    Returns:\n        The encoded DataFrame.\n    \"\"\"\n    return super()._encode_template(df, freeze=freeze)\n</code></pre>"}]}